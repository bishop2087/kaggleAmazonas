{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "960baa96",
   "metadata": {},
   "source": [
    "# Project Notes\n",
    "this is about saving the amazon rainforest\n",
    "\n",
    "here we try to improve level1 results (0.899) by\n",
    "- input data normalization and some clean up\n",
    "- data augmentation\n",
    "\n",
    "ressources for replacing the deprecated image data generator module:\n",
    "- https://www.tensorflow.org/tutorials/load_data/images\n",
    "- https://www.tensorflow.org/guide/keras/preprocessing_layers\n",
    "- https://www.tensorflow.org/tutorials/images/data_augmentation\n",
    "\n",
    "## result\n",
    "- val_loss: 0.1050 - val_binary_accuracy: 0.9592\n",
    "- private score: 0.906\n",
    "- public score: 0.909"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549c233e",
   "metadata": {},
   "source": [
    "# 1.Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3880ec97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "from six import string_types\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "import scipy\n",
    "from skimage import io\n",
    "from scipy import ndimage\n",
    "from IPython.display import display\n",
    "\n",
    "import random\n",
    "from time import time\n",
    "from glob import glob\n",
    "\n",
    "# from tqdm.notebook import tqdm\n",
    "from collections import Counter\n",
    "# import dill as pickle\n",
    "\n",
    "from plotly import graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import cv2\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import fbeta_score, confusion_matrix\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from torch.utils.data import DataLoader, Dataset\n",
    "# from torchvision import transforms as T, models\n",
    "# from torch.optim import Adam\n",
    "# from torch.optim.lr_scheduler import StepLR\n",
    "# !pip install -q torchsummary --user\n",
    "# from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c8bc34",
   "metadata": {},
   "source": [
    "# 2.Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00e8a13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLANET_KAGGLE_LEVEL_ROOT = os.path.abspath(\"C:/Users/janni/RomansCode/Rainforest ML Projekt\")\n",
    "PLANET_KAGGLE_ROOT = os.path.abspath(\"C:/Users/janni/RomansCode/Rainforest ML Projekt/input\")\n",
    "PLANET_KAGGLE_JPEG_DIR = os.path.join(PLANET_KAGGLE_ROOT, 'train-jpg')\n",
    "PLANET_KAGGLE_JPG_TEST_DIR = os.path.join(PLANET_KAGGLE_ROOT, 'test-jpg')\n",
    "PLANET_KAGGLE_JPG_TEST_EXTRA_DIR = os.path.join(PLANET_KAGGLE_ROOT, 'test-jpg-additional')\n",
    "PLANET_KAGGLE_LABEL_CSV = os.path.join(PLANET_KAGGLE_ROOT, 'train_v2.csv')\n",
    "PLANET_KAGGLE_SUBMISSION_CSV = os.path.join(PLANET_KAGGLE_ROOT, 'sample_submission_orig.csv')\n",
    "\n",
    "assert os.path.exists(PLANET_KAGGLE_ROOT)\n",
    "assert os.path.exists(PLANET_KAGGLE_JPEG_DIR)\n",
    "assert os.path.exists(PLANET_KAGGLE_LABEL_CSV)\n",
    "assert os.path.exists(PLANET_KAGGLE_JPG_TEST_DIR)\n",
    "assert os.path.exists(PLANET_KAGGLE_JPG_TEST_EXTRA_DIR)\n",
    "\n",
    "assert os.path.exists(PLANET_KAGGLE_ROOT)\n",
    "assert os.path.exists(PLANET_KAGGLE_JPEG_DIR)\n",
    "\n",
    "assert os.path.exists(PLANET_KAGGLE_LABEL_CSV)\n",
    "\n",
    "assert os.path.exists(PLANET_KAGGLE_JPG_TEST_DIR)\n",
    "assert os.path.exists(PLANET_KAGGLE_JPG_TEST_EXTRA_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f1eaabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "exec_train = False\n",
    "exec_load = True\n",
    "exec_test = False\n",
    "exec_submit = False\n",
    "exec_val = True\n",
    "exec_visualize = False\n",
    "\n",
    "use_best_thresholds = True\n",
    "manual_threshs = [0.2]*17 #only necessary if you dont use the best thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64af0a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>haze primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>agriculture clear primary water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>clear primary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>agriculture clear habitation primary road</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name                                       tags\n",
       "0    train_0                               haze primary\n",
       "1    train_1            agriculture clear primary water\n",
       "2    train_2                              clear primary\n",
       "3    train_3                              clear primary\n",
       "4    train_4  agriculture clear habitation primary road"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df = pd.read_csv(PLANET_KAGGLE_LABEL_CSV)\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30708107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build list with unique labels\n",
    "label_list = []\n",
    "for tag_str in labels_df.tags.values:\n",
    "    labels = tag_str.split(' ')\n",
    "    for label in labels:\n",
    "        if label not in label_list:\n",
    "            label_list.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "131974ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>tags</th>\n",
       "      <th>haze</th>\n",
       "      <th>primary</th>\n",
       "      <th>agriculture</th>\n",
       "      <th>clear</th>\n",
       "      <th>water</th>\n",
       "      <th>habitation</th>\n",
       "      <th>road</th>\n",
       "      <th>cultivation</th>\n",
       "      <th>slash_burn</th>\n",
       "      <th>cloudy</th>\n",
       "      <th>partly_cloudy</th>\n",
       "      <th>conventional_mine</th>\n",
       "      <th>bare_ground</th>\n",
       "      <th>artisinal_mine</th>\n",
       "      <th>blooming</th>\n",
       "      <th>selective_logging</th>\n",
       "      <th>blow_down</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>haze primary</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>agriculture clear primary water</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>clear primary</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>clear primary</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>agriculture clear habitation primary road</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name                                       tags  haze  primary  \\\n",
       "0    train_0                               haze primary     1        1   \n",
       "1    train_1            agriculture clear primary water     0        1   \n",
       "2    train_2                              clear primary     0        1   \n",
       "3    train_3                              clear primary     0        1   \n",
       "4    train_4  agriculture clear habitation primary road     0        1   \n",
       "\n",
       "   agriculture  clear  water  habitation  road  cultivation  slash_burn  \\\n",
       "0            0      0      0           0     0            0           0   \n",
       "1            1      1      1           0     0            0           0   \n",
       "2            0      1      0           0     0            0           0   \n",
       "3            0      1      0           0     0            0           0   \n",
       "4            1      1      0           1     1            0           0   \n",
       "\n",
       "   cloudy  partly_cloudy  conventional_mine  bare_ground  artisinal_mine  \\\n",
       "0       0              0                  0            0               0   \n",
       "1       0              0                  0            0               0   \n",
       "2       0              0                  0            0               0   \n",
       "3       0              0                  0            0               0   \n",
       "4       0              0                  0            0               0   \n",
       "\n",
       "   blooming  selective_logging  blow_down  \n",
       "0         0                  0          0  \n",
       "1         0                  0          0  \n",
       "2         0                  0          0  \n",
       "3         0                  0          0  \n",
       "4         0                  0          0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add onehot features for every label\n",
    "labels_df_original = labels_df.copy()\n",
    "for label in label_list:\n",
    "    labels_df[label] = labels_df['tags'].apply(lambda x: 1 if label in x.split(' ') else 0)\n",
    "# Display head\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a6c3d2",
   "metadata": {},
   "source": [
    "# get a simple one working\n",
    "https://www.kaggle.com/code/emekeh/planet-dataset-stage-d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97fabbf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\janni\\anaconda3\\envs\\ml_python3_7\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\janni\\anaconda3\\envs\\ml_python3_7\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\janni\\anaconda3\\envs\\ml_python3_7\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\janni\\anaconda3\\envs\\ml_python3_7\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\janni\\anaconda3\\envs\\ml_python3_7\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\janni\\anaconda3\\envs\\ml_python3_7\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\janni\\anaconda3\\envs\\ml_python3_7\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\janni\\anaconda3\\envs\\ml_python3_7\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\janni\\anaconda3\\envs\\ml_python3_7\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\janni\\anaconda3\\envs\\ml_python3_7\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\janni\\anaconda3\\envs\\ml_python3_7\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\janni\\anaconda3\\envs\\ml_python3_7\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing the necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import gc \n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 \n",
    "import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "#from tqdm import tqdm \n",
    "from matplotlib.image import imread\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import optimizers\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94f4370e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# filter warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2d23bef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect() #Frequently used to avoid session crashing due to memory exhaustion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c07161e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>tags</th>\n",
       "      <th>haze</th>\n",
       "      <th>primary</th>\n",
       "      <th>agriculture</th>\n",
       "      <th>clear</th>\n",
       "      <th>water</th>\n",
       "      <th>habitation</th>\n",
       "      <th>road</th>\n",
       "      <th>cultivation</th>\n",
       "      <th>slash_burn</th>\n",
       "      <th>cloudy</th>\n",
       "      <th>partly_cloudy</th>\n",
       "      <th>conventional_mine</th>\n",
       "      <th>bare_ground</th>\n",
       "      <th>artisinal_mine</th>\n",
       "      <th>blooming</th>\n",
       "      <th>selective_logging</th>\n",
       "      <th>blow_down</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0.jpg</td>\n",
       "      <td>haze primary</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1.jpg</td>\n",
       "      <td>agriculture clear primary water</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2.jpg</td>\n",
       "      <td>clear primary</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3.jpg</td>\n",
       "      <td>clear primary</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4.jpg</td>\n",
       "      <td>agriculture clear habitation primary road</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    image_name                                       tags  haze  primary  \\\n",
       "0  train_0.jpg                               haze primary     1        1   \n",
       "1  train_1.jpg            agriculture clear primary water     0        1   \n",
       "2  train_2.jpg                              clear primary     0        1   \n",
       "3  train_3.jpg                              clear primary     0        1   \n",
       "4  train_4.jpg  agriculture clear habitation primary road     0        1   \n",
       "\n",
       "   agriculture  clear  water  habitation  road  cultivation  slash_burn  \\\n",
       "0            0      0      0           0     0            0           0   \n",
       "1            1      1      1           0     0            0           0   \n",
       "2            0      1      0           0     0            0           0   \n",
       "3            0      1      0           0     0            0           0   \n",
       "4            1      1      0           1     1            0           0   \n",
       "\n",
       "   cloudy  partly_cloudy  conventional_mine  bare_ground  artisinal_mine  \\\n",
       "0       0              0                  0            0               0   \n",
       "1       0              0                  0            0               0   \n",
       "2       0              0                  0            0               0   \n",
       "3       0              0                  0            0               0   \n",
       "4       0              0                  0            0               0   \n",
       "\n",
       "   blooming  selective_logging  blow_down  \n",
       "0         0                  0          0  \n",
       "1         0                  0          0  \n",
       "2         0                  0          0  \n",
       "3         0                  0          0  \n",
       "4         0                  0          0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing imagedatagenerator with a validation split of 0.2\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255., validation_split = 0.2, featurewise_std_normalization=True, horizontal_flip=True, vertical_flip=True, featurewise_center=True)\n",
    "\n",
    "#we convert to dataframe used up to this point so that it fits into this guy's architecture\n",
    "\n",
    "# adding .jpg extension to the column image_name so as to have same name format as the image files\n",
    "train_df1 = labels_df.copy()\n",
    "train_df1['image_name'] = labels_df['image_name'].apply(lambda x: '{}.jpg'.format(x))\n",
    "# train_df1['image_name'] = labels_df['image_name'].apply(lambda x: '{}.tif'.format(x))\n",
    "train_df1.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de33096e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['haze',\n",
       " 'primary',\n",
       " 'agriculture',\n",
       " 'clear',\n",
       " 'water',\n",
       " 'habitation',\n",
       " 'road',\n",
       " 'cultivation',\n",
       " 'slash_burn',\n",
       " 'cloudy',\n",
       " 'partly_cloudy',\n",
       " 'conventional_mine',\n",
       " 'bare_ground',\n",
       " 'artisinal_mine',\n",
       " 'blooming',\n",
       " 'selective_logging',\n",
       " 'blow_down']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = list(train_df1.columns[2:])\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96103b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32384 validated image filenames.\n",
      "Found 8095 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# # Generating train data generator \n",
    "train_generator = train_datagen.flow_from_dataframe(dataframe=train_df1,\n",
    "                                                    directory =PLANET_KAGGLE_JPEG_DIR, \n",
    "                                                    x_col='image_name', y_col=columns, subset='training', \n",
    "                                                    batch_size=32,seed=42, shuffle=True, \n",
    "                                                    class_mode='raw', target_size=(128,128))\n",
    "\n",
    "#generating validation data which is expected to be 20% of the train dataset since validation split is 0.2\n",
    "val_generator = train_datagen.flow_from_dataframe(dataframe=train_df1,\n",
    "                                                  directory =PLANET_KAGGLE_JPEG_DIR, \n",
    "                                                  x_col='image_name', y_col=columns, subset='validation', \n",
    "                                                  batch_size=32,seed=42, shuffle=True, \n",
    "                                                  class_mode='raw', target_size=(128,128))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e9f8244",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting up step size for training and validation image data\n",
    "step_train_size = int(np.ceil(train_generator.samples / train_generator.batch_size))\n",
    "step_val_size = int(np.ceil(val_generator.samples / val_generator.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0c11205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63c00244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "def cnn_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    # Convolution layers\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(128, 128, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Flatten layer\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Fully connected layers\n",
    "    model.add(Dense(units=512, activation='relu'))\n",
    "    model.add(Dropout(rate=0.5))\n",
    "    model.add(Dense(units=17, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(lr=0.0002), \n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['binary_accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e1342b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.optimizers.Adam object at 0x00000153A4A7CCF8>\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(learning_rate=0.01)\n",
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f59bbc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\janni\\anaconda3\\envs\\ml_python3_7\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\janni\\anaconda3\\envs\\ml_python3_7\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 256)       295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16384)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               8389120   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 17)                8721      \n",
      "=================================================================\n",
      "Total params: 8,786,257\n",
      "Trainable params: 8,786,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#initialize the model\n",
    "model = cnn_model()\n",
    "\n",
    "# Preview the model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b65b3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define callbacks\n",
    "earlystop = EarlyStopping(monitor='val_binary_accuracy', \n",
    "                          patience=3, verbose=1, \n",
    "                          mode='max', \n",
    "                          restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24f8faa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20d13b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model \n",
    "if exec_train == True:\n",
    "    history = model.fit(x = train_generator, \n",
    "                    steps_per_epoch = step_train_size, \n",
    "                    validation_data = val_generator,\n",
    "                    validation_steps = step_val_size,\n",
    "                    epochs = 40, \n",
    "                    callbacks = [earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1347cc8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (file signature not found)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10648\\2563235920.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mexec_load\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/Users/janni/RomansCode/Rainforest ML Projekt/l4/checkpoint'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\ml_python3_7\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36mload_wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    490\u001b[0m                 \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_filepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 492\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mload_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mload_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ml_python3_7\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[0;32m   1219\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1220\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'`load_weights` requires h5py.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1221\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1222\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m'layer_names'\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m'model_weights'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m                 \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model_weights'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ml_python3_7\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, **kwds)\u001b[0m\n\u001b[0;32m    531\u001b[0m                                  \u001b[0mfs_persist\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfs_threshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfs_threshold\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[1;32m--> 533\u001b[1;33m                 \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    534\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ml_python3_7\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    224\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m             \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to open file (file signature not found)"
     ]
    }
   ],
   "source": [
    "if exec_load == True:\n",
    "    model.load_weights('C:/Users/janni/RomansCode/Rainforest ML Projekt/l4/checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2705ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24b3c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation accuracy and loss curves\n",
    "if exec_train == True:\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['binary_accuracy'])\n",
    "    plt.plot(history.history['val_binary_accuracy'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['training', 'validation'], loc='upper left')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['training', 'validation'], loc='upper left')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f683f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if exec_val == True:\n",
    "\n",
    "    file_names_val = val_generator.filenames\n",
    "\n",
    "    val_generator.reset()\n",
    "    pred_val = model.predict(val_generator, steps = step_val_size, verbose = 1)\n",
    "\n",
    "    Y_val = val_generator.labels\n",
    "    Y_hat_val = pred_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeebcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_thresholds(Y_hat, Y):\n",
    "    N_tags = Y.shape[1]\n",
    "    best_threshs = [0.2] * N_tags\n",
    "    resolution = 100\n",
    "    for jdx in range(N_tags):\n",
    "        best_score = 0\n",
    "        #threshs = np.zeros_like(best_threshs)\n",
    "        threshs = best_threshs.copy()\n",
    "        for kdx in range(resolution):\n",
    "            kdx /= resolution\n",
    "            threshs[jdx] = kdx\n",
    "            Y_hat_thresh = (Y_hat > threshs).astype(float)\n",
    "            score = fbeta_score(Y, Y_hat_thresh, beta=2, average=\"samples\")\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_threshs[jdx] = kdx\n",
    "    \n",
    "    global_best_score = fbeta_score(Y, (Y_hat > best_threshs).astype(float), beta=2, average=\"samples\")\n",
    "    print(f\"threshs: {best_threshs} -- best score: {global_best_score}\")\n",
    "    \n",
    "    return best_threshs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7b0252",
   "metadata": {},
   "outputs": [],
   "source": [
    "if exec_val == True:\n",
    "    \n",
    "    internal_test_datagen = ImageDataGenerator(rescale = 1./255., featurewise_std_normalization=True, featurewise_center=True)\n",
    "\n",
    "    \n",
    "    internal_test_df = labels_df.iloc[:8095][:].reset_index().drop('index', axis =1)\n",
    "    \n",
    "    internal_test_generator = internal_test_datagen.flow_from_dataframe(dataframe=internal_test_df,\n",
    "                                                  directory =PLANET_KAGGLE_JPEG_DIR, \n",
    "                                                  x_col='image_name', y_col=columns, \n",
    "                                                  batch_size=32,seed=42, shuffle=False, \n",
    "                                                  class_mode='raw', target_size=(128,128))\n",
    "    \n",
    "    Y_hat_internal_test = model.predict(internal_test_generator, steps = step_val_size, verbose = 1)\n",
    "    Y_internal_test = internal_test_df[columns]\n",
    "    \n",
    "    \n",
    "    best_threshs = find_best_thresholds(Y_hat=Y_hat_internal_test, Y=Y_internal_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d7d053",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_threshs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6d77f5",
   "metadata": {},
   "source": [
    "# submit you fucking result and end this \"durchstich\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d16bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339dbe79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLANET_KAGGLE_ROOT\n",
    "# PLANET_KAGGLE_JPEG_DIR\n",
    "# PLANET_KAGGLE_TIF_DIR\n",
    "# PLANET_KAGGLE_TIF_TEST_DIR\n",
    "# PLANET_KAGGLE_JPG_TEST_DIR\n",
    "# PLANET_KAGGLE_JPG_TEST_EXTRA_DIR\n",
    "# PLANET_KAGGLE_LABEL_CSV\n",
    "# PLANET_KAGGLE_SUBMISSION_CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c87967",
   "metadata": {},
   "outputs": [],
   "source": [
    "##adding .jpg extension to image name in the sample submission file\n",
    "if exec_submit == True:\n",
    "    sample_submission = pd.read_csv(PLANET_KAGGLE_SUBMISSION_CSV)\n",
    "    sample_submission1 = sample_submission.copy()\n",
    "    sample_submission1['image_name'] = sample_submission1['image_name'].apply(lambda x: '{}.jpg'.format(x))\n",
    "    sample_submission1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8c3ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the sample submission file into two splits,\n",
    "# first test1_df contains the first 40669 images \n",
    "if exec_submit == True:\n",
    "    test_df1 = sample_submission1.iloc[:40669]['image_name'].reset_index().drop('index', axis =1)\n",
    "    test_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba6bdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize imagedatagenerator for the test images and also rescaling\n",
    "if exec_submit == True:\n",
    "    test_datagen = ImageDataGenerator(rescale = 1/255., featurewise_std_normalization=True, featurewise_center=True)\n",
    "\n",
    "    #creating a generator for the images found in the first test image files\n",
    "    test_gen = test_datagen.flow_from_dataframe(dataframe=test_df1, \n",
    "                                                directory=PLANET_KAGGLE_JPG_TEST_DIR, \n",
    "                                                x_col=\"image_name\", \n",
    "                                                y_col=None, \n",
    "                                                batch_size=32,\n",
    "                                                seed=42,\n",
    "                                                shuffle=False, \n",
    "                                                class_mode=None, \n",
    "                                                target_size=(128,128))\n",
    "\n",
    "    step_test_size1 = int(np.ceil(test_gen.samples/test_gen.batch_size))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8ef933",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first, we reset the test generator to avoid shuffling of index \n",
    "if exec_submit == True:\n",
    "    test_gen.reset()\n",
    "    pred = model.predict(test_gen, steps=step_test_size1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ac3dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the filenames in the generator using the attribute .filenames\n",
    "if exec_submit == True:\n",
    "    file_names = test_gen.filenames\n",
    "\n",
    "    # Convert the predicted values to a dataframe and join two labels together if prob(occurrance of the label) > thresholds \n",
    "    pred_tags = pd.DataFrame(pred)\n",
    "    if use_best_thresholds == True:\n",
    "        pred_tags = pred_tags.apply(lambda x: ' '.join(np.array(label_list)[x > best_threshs]), axis = 1)\n",
    "    else:\n",
    "        pred_tags = pred_tags.apply(lambda x: ' '.join(np.array(label_list)[x > manual_threshs]), axis = 1)\n",
    "        \n",
    "    #then the result should look like this \n",
    "    result1 = pd.DataFrame({'image_name': file_names, 'tags': pred_tags})\n",
    "    result1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db449ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#second batch of the test dataset\n",
    "if exec_submit == True:\n",
    "    additional_df = sample_submission1.iloc[40669:]['image_name'].reset_index().drop('index', axis =1)\n",
    "    additional_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008d2086",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a generator for the second batch of test image files\n",
    "if exec_submit == True:\n",
    "    test_gen1 = test_datagen.flow_from_dataframe(dataframe=additional_df, \n",
    "                                                    directory=PLANET_KAGGLE_JPG_TEST_EXTRA_DIR, \n",
    "                                                    x_col='image_name', \n",
    "                                                    y_col=None, \n",
    "                                                    batch_size=32, \n",
    "                                                    shuffle=False, \n",
    "                                                    class_mode=None, \n",
    "                                                    target_size=(128,128))\n",
    "\n",
    "    step_test_size2 = int(np.ceil(test_gen1.samples/test_gen1.batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68952ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we reset the generator to avoid shuffling, then make prediction on the generator\n",
    "if exec_submit == True:\n",
    "    test_gen1.reset()\n",
    "    pred1 = model.predict(test_gen1, steps = step_test_size2, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e48ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is to get the filenames in the generator using the attribute .filenames\n",
    "if exec_submit == True:\n",
    "    file_names1 = test_gen1.filenames\n",
    "\n",
    "    #convert the predicted values to a dataframe\n",
    "    #join two labels together if the prob(occurrance of the label) > 0.5\n",
    "    pred_tags1 = pd.DataFrame(pred1)\n",
    "    if use_best_thresholds == True:\n",
    "        pred_tags1 = pred_tags1.apply(lambda x: ' '.join(np.array(label_list)[x > best_threshs]), axis = 1)\n",
    "    else:\n",
    "        pred_tags1 = pred_tags1.apply(lambda x: ' '.join(np.array(label_list)[x > manual_threshs]), axis = 1)\n",
    "\n",
    "    result2 = pd.DataFrame({'image_name': file_names1, 'tags': pred_tags1})\n",
    "    result2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982176ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final result of the predicted tags for the test images,\n",
    "# we need to concat the first and second results in \n",
    "#that order to avoid shuffling the index\n",
    "if exec_submit == True:\n",
    "    final_df = pd.concat([result1, result2])\n",
    "\n",
    "    final_df = final_df.reset_index().drop('index', axis =1)\n",
    "\n",
    "    print(final_df.shape)\n",
    "    final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb02b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the .jpg extension from the image_name of the last_result \n",
    "if exec_submit == True:\n",
    "    final_df['image_name'] = final_df['image_name'].apply(lambda x: x[:-4])\n",
    "    final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757aba23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we save the result to a csv file using the .to_csv() \n",
    "# method and setting the index to false.\n",
    "if exec_submit == True:\n",
    "    final_df.to_csv('l4/submissionl4.csv', index = False)\n",
    "    model.save_weights('l4/l4_my_checkpoint')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c5c1b6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77df4081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the weights\n",
    "# model.save_weights('l3_my_checkpoint')\n",
    "\n",
    "# # Create a new model instance\n",
    "# model = create_model()\n",
    "\n",
    "# # Restore the weights\n",
    "# model.load_weights('./checkpoints/my_checkpoint')\n",
    "\n",
    "# # Evaluate the model\n",
    "# loss, acc = model.evaluate(test_images, test_labels, verbose=2)\n",
    "# print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d337200",
   "metadata": {},
   "source": [
    "# results: visualization & analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178915db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gc.collect()\n",
    "# model = cnn_model()\n",
    "# model.load_weights('l1_my_checkpoint')\n",
    "\n",
    "# # # Evaluate the model to make sure you loaded the right one\n",
    "# loss, acc = model.evaluate(val_generator, verbose=2)\n",
    "# print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d06557",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visual1a\n",
    "#I would like to look at the pictures that I got wromg and see the actual labels vs the predicted ones. \n",
    "#this plot shall display 17 pics in a vertical line. so one example per label. in the second colum you have the true labels\n",
    "#and in the third line you have the predicted labels\n",
    "if exec_visualize == True:\n",
    "    file_names = val_generator.filenames\n",
    "    # Convert the predicted values to a dataframe and join two labels together if prob(occurrance of the label) > alpha\n",
    "    pred = model.predict(val_generator, steps=step_val_size, verbose=1)\n",
    "    pred_tags = pd.DataFrame(pred)\n",
    "    pred_tags = pred_tags.apply(lambda x: ' '.join(np.array(label_list)[x > 0.2]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c00c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "if exec_visualize == True:\n",
    "    #then the result should look like this \n",
    "    prediction_val = pd.DataFrame({'image_name': file_names, 'tags': pred_tags})\n",
    "    \n",
    "    #get a one hot encoded prediction table\n",
    "    for label in label_list:\n",
    "        prediction_val[label] = prediction_val['tags'].apply(lambda x: 1 if label in x.split(' ') else 0)\n",
    "    # Display head\n",
    "    #here we have the truth table. note that we have val+train combined here\n",
    "    truth_val = labels_df\n",
    "    truth_val['image_name'] = truth_val['image_name'].apply(lambda x: '{}.jpg'.format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc40179",
   "metadata": {},
   "outputs": [],
   "source": [
    "if exec_visualize == True:\n",
    "    #per one hot label look for the rows where the pred does not match the truth\n",
    "    label_to_print_index = 0\n",
    "    label_to_print = label_list[label_to_print_index]\n",
    "    \n",
    "    #_x corresponds to the val set\n",
    "    val_joined_pred=pd.merge(prediction_val,truth_val, on='image_name')\n",
    "#     for label ined_pred[label+'correct'] = val_joined_pred[label+'_x'].apply(lambda x: 1 if x == val_joined_pred[label+'_y'] else 0)\n",
    " \n",
    "    for label in label_list:\n",
    "        val_joined_pred[label+'_correct'] = -1\n",
    "        for index, row in val_joined_pred.iterrows():\n",
    "            if row[label+'_x'] == row[label+'_y']:\n",
    "                val_joined_pred.loc[index,label+'_correct'] = 1\n",
    "            else:\n",
    "                val_joined_pred.loc[index,label+'_correct'] = 0\n",
    "                \n",
    "  #df_wrong_prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacfe76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if exec_visualize == True:\n",
    "    #extract randomly one pic from this list\n",
    "    list_sampled_true_pos = []  \n",
    "    list_sampled_false_pos = []\n",
    "    list_sampled_true_neg  = []\n",
    "    list_sampled_false_neg = []\n",
    "    \n",
    "\n",
    "    for label in label_list:\n",
    "\n",
    "        #get the true positives\n",
    "        temp_dict = {}\n",
    "        temp_dict['chosen_label'] = label\n",
    "        df_sampled_temp = val_joined_pred[(val_joined_pred[label+'_correct'] ==1) & (val_joined_pred[label+'_y'] ==1)]\n",
    "        if not df_sampled_temp.empty:\n",
    "            df_sampled_temp = df_sampled_temp.sample(1, replace=True)\n",
    "            temp_dict['image_name'] = list(df_sampled_temp['image_name'])[0]\n",
    "            temp_dict['true_labels'] = list(df_sampled_temp['tags_y'])\n",
    "            temp_dict['predicted_labels'] = list(df_sampled_temp['tags_x'])\n",
    "        else:\n",
    "            temp_dict['image_name'] = \"empty\"\n",
    "            temp_dict['true_labels'] = \"empty\"\n",
    "            temp_dict['predicted_labels'] = \"empty\"\n",
    "        list_sampled_true_pos.append(temp_dict)\n",
    "        \n",
    "        #get the false positives\n",
    "        temp_dict = {}\n",
    "        temp_dict['chosen_label'] = label\n",
    "        df_sampled_temp = val_joined_pred[(val_joined_pred[label+'_correct'] ==0) & (val_joined_pred[label+'_y'] ==0)]\n",
    "        if not df_sampled_temp.empty:\n",
    "            df_sampled_temp = df_sampled_temp.sample(1, replace=True)\n",
    "            temp_dict['image_name'] = list(df_sampled_temp['image_name'])[0]\n",
    "            temp_dict['true_labels'] = list(df_sampled_temp['tags_y'])\n",
    "            temp_dict['predicted_labels'] = list(df_sampled_temp['tags_x'])\n",
    "        else:\n",
    "            temp_dict['image_name'] = \"empty\"\n",
    "            temp_dict['true_labels'] = \"empty\"\n",
    "            temp_dict['predicted_labels'] = \"empty\"\n",
    "        list_sampled_false_pos.append(temp_dict)\n",
    "        \n",
    "        #get the true negatives\n",
    "        temp_dict = {}\n",
    "        temp_dict['chosen_label'] = label\n",
    "        df_sampled_temp = val_joined_pred[(val_joined_pred[label+'_correct'] ==1) & (val_joined_pred[label+'_y'] ==0)]\n",
    "        if not df_sampled_temp.empty:\n",
    "            df_sampled_temp = df_sampled_temp.sample(1, replace=True)\n",
    "            temp_dict['image_name'] = list(df_sampled_temp['image_name'])[0]\n",
    "            temp_dict['true_labels'] = list(df_sampled_temp['tags_y'])\n",
    "            temp_dict['predicted_labels'] = list(df_sampled_temp['tags_x'])\n",
    "        else:\n",
    "            temp_dict['image_name'] = \"empty\"\n",
    "            temp_dict['true_labels'] = \"empty\"\n",
    "            temp_dict['predicted_labels'] = \"empty\"\n",
    "        list_sampled_true_neg.append(temp_dict)\n",
    "        \n",
    "        #get the false negatives\n",
    "        temp_dict = {}\n",
    "        temp_dict['chosen_label'] = label\n",
    "        df_sampled_temp = val_joined_pred[(val_joined_pred[label+'_correct'] ==0) & (val_joined_pred[label+'_y'] ==1)]\n",
    "        if not df_sampled_temp.empty:\n",
    "            df_sampled_temp = df_sampled_temp.sample(1, replace=True)\n",
    "            temp_dict['image_name'] = list(df_sampled_temp['image_name'])[0]\n",
    "            temp_dict['true_labels'] = list(df_sampled_temp['tags_y'])\n",
    "            temp_dict['predicted_labels'] = list(df_sampled_temp['tags_x'])\n",
    "        else:\n",
    "            temp_dict['image_name'] = \"empty\"\n",
    "            temp_dict['true_labels'] = \"empty\"\n",
    "            temp_dict['predicted_labels'] = \"empty\"\n",
    "        list_sampled_false_neg.append(temp_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec466a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(filename):\n",
    "    '''Look through the directory tree to find the image you specified\n",
    "    (e.g. train_10.tif vs. train_10.jpg)'''\n",
    "    for dirname in os.listdir(PLANET_KAGGLE_ROOT):\n",
    "        path = os.path.abspath(os.path.join(PLANET_KAGGLE_ROOT, dirname, filename))\n",
    "        if os.path.exists(path):\n",
    "            print('Found image {}'.format(path))\n",
    "            return io.imread(path)\n",
    "    # if you reach this line, you didn't find the image you're looking for\n",
    "    print('Load failed: could not find image {}'.format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f96301",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c83da21",
   "metadata": {},
   "outputs": [],
   "source": [
    "if exec_visualize == True:\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(30, 100)\n",
    "    fig.suptitle('confusion matric pictures per target label', fontsize=16)\n",
    "    for i, sample in enumerate(list_sampled_true_pos):\n",
    "        a = fig.add_subplot(17, 4, i*4 +1)\n",
    "        a.set_title(\"true_pos:\" + sample['chosen_label'] + \"\\n\"+ \"true:\"+str(sample['true_labels']) + \"\\n\"+ \"predicted:\"+ str(sample['predicted_labels']))\n",
    "        if sample['image_name'] != \"empty\":\n",
    "            plt.imshow(load_image(sample['image_name']))\n",
    "        else:\n",
    "            plt.imshow(load_image('train_blanc.jpg'))\n",
    "    for i, sample in enumerate(list_sampled_false_pos):\n",
    "        a = fig.add_subplot(17, 4, i*4+2)\n",
    "        a.set_title(\"false_pos:\" + sample['chosen_label'] + \"\\n\"+ \"true:\"+str(sample['true_labels']) + \"\\n\"+ \"predicted:\"+ str(sample['predicted_labels']))\n",
    "        if sample['image_name'] != \"empty\":\n",
    "            plt.imshow(load_image(sample['image_name']))\n",
    "        else:\n",
    "            plt.imshow(load_image('train_blanc.jpg'))\n",
    "    for i, sample in enumerate(list_sampled_true_neg):\n",
    "        a = fig.add_subplot(17, 4, i*4+3)\n",
    "        a.set_title(\"true_neg:\" + sample['chosen_label'] + \"\\n\"+ \"true:\"+str(sample['true_labels']) + \"\\n\"+ \"predicted:\"+ str(sample['predicted_labels']))\n",
    "        if sample['image_name'] != \"empty\":\n",
    "            plt.imshow(load_image(sample['image_name']))\n",
    "        else:\n",
    "            plt.imshow(load_image('train_blanc.jpg'))\n",
    "    for i, sample in enumerate(list_sampled_false_neg):\n",
    "        a = fig.add_subplot(17, 4, i*4+4)\n",
    "        a.set_title(\"false_neg:\" + sample['chosen_label'] + \"\\n\"+ \"true:\"+str(sample['true_labels']) + \"\\n\"+ \"predicted:\"+ str(sample['predicted_labels']))\n",
    "        if sample['image_name'] != \"empty\":\n",
    "            plt.imshow(load_image(sample['image_name']))\n",
    "        else:\n",
    "            plt.imshow(load_image('train_blanc.jpg'))\n",
    "    plt.savefig(\"l4/predictions_l4_rgb.jpg\",  dpi='figure', format=\"jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2aa8da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visual1b\n",
    "#now it would be nice to see the false negatives in their r g b n slices\n",
    "\n",
    "\n",
    "if exec_visualize == True:\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(30, 100)\n",
    "    fig.suptitle('false negatives per target label', fontsize=16)\n",
    "    for i, sample in enumerate(list_sampled_false_neg):\n",
    "        \n",
    "        if sample['image_name'] != \"empty\":\n",
    "            bgrn_image = load_image(sample['image_name'].replace(\".jpg\", \".tif\"))\n",
    "            b, g, r, nir = bgrn_image[:, :, 0], bgrn_image[:, :, 1], bgrn_image[:, :, 2], bgrn_image[:, :, 3]\n",
    "        else:\n",
    "            b= load_image('train_blanc.jpg')\n",
    "            g = b\n",
    "            r = b\n",
    "            nir = b\n",
    "        \n",
    "        a = fig.add_subplot(17, 4, i*4 +1)\n",
    "        a.set_title(\"b:\" + sample['chosen_label'] + \"\\n\"+ \"true:\"+str(sample['true_labels']) + \"\\n\"+ \"predicted:\"+ str(sample['predicted_labels']))\n",
    "        plt.imshow(b)\n",
    "            \n",
    "        a = fig.add_subplot(17, 4, i*4+2)\n",
    "        a.set_title(\"g:\" + sample['chosen_label'] )\n",
    "        plt.imshow(g)\n",
    "            \n",
    "        a = fig.add_subplot(17, 4, i*4+3)\n",
    "        a.set_title(\"r:\" + sample['chosen_label'] )\n",
    "        plt.imshow(r)\n",
    "\n",
    "        a = fig.add_subplot(17, 4, i*4+4)\n",
    "        a.set_title(\"nir:\" + sample['chosen_label'] )\n",
    "        plt.imshow(nir)\n",
    "            \n",
    "    plt.savefig(\"l4/predictions_l4_rgbn.jpg\",  dpi='figure', format=\"jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc637201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29d572d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bbded5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visual5\n",
    "#I would like to have the average of the prodiction probs plottet per label for both cases: Y_hat =1 and Y_hat =0\n",
    "\n",
    "if exec_visualize == True:\n",
    "\n",
    "    #y-hat is alwyas the predicted not the true value\n",
    "    train_results_val = val_generator.labels\n",
    "    train_results_val_hat = pred\n",
    "\n",
    "    Y_val = np.array(train_results_val)\n",
    "    Y_hat_val = np.array(train_results_val_hat)\n",
    "\n",
    "    label_dict = {}\n",
    "    for i, label in enumerate(label_list):\n",
    "        label_dict[label] = i\n",
    "        \n",
    "    \n",
    "    pos_probas, neg_probas = [], []\n",
    "    for class_, idx in label_dict.items():\n",
    "        pos_probas.append(Y_hat_val[np.where(Y_val[:, idx] != 0), idx].mean())\n",
    "        neg_probas.append(Y_hat_val[np.where(Y_val[:, idx] == 0), idx].mean())\n",
    "    go.Figure([\n",
    "        go.Bar(x=list(label_dict), y=pos_probas, name=\"Y_hat proba | Y = 1\"),\n",
    "        go.Bar(x=list(label_dict), y=neg_probas, name=\"Y_hat proba | Y = 0\")\n",
    "    ]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4480eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visual6\n",
    "#I would like tos see how many labels were predicted\n",
    "\n",
    "if exec_visualize == True:\n",
    "    prediction_val[label_list].sum().sort_values().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0d6f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visual4\n",
    "#I would like to see the coooccurence matrices per label group and have them compared to the one of the training data\n",
    "if exec_visualize == True:\n",
    "    def make_cooccurence_matrix(label_list):\n",
    "        numeric_df = prediction_val[label_list]; \n",
    "        c_matrix = numeric_df.T.dot(numeric_df)\n",
    "        sns.heatmap(c_matrix)\n",
    "        return c_matrix\n",
    "\n",
    "    weather_labels = ['clear', 'partly_cloudy', 'haze', 'cloudy']\n",
    "    land_labels = ['primary', 'agriculture', 'water', 'cultivation', 'habitation']\n",
    "    rare_labels = [l for l in label_list if prediction_val[label_list].sum()[l] < 1000]\n",
    "    \n",
    "    # Compute the co-ocurrence matrix\n",
    "    make_cooccurence_matrix(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1225685",
   "metadata": {},
   "outputs": [],
   "source": [
    "if exec_visualize == True:\n",
    "\n",
    "    \n",
    "    # Compute the co-ocurrence matrix\n",
    "    make_cooccurence_matrix(weather_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90fdf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "if exec_visualize == True:\n",
    "\n",
    "    \n",
    "    # Compute the co-ocurrence matrix\n",
    "    make_cooccurence_matrix(land_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2033c50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if exec_visualize == True:\n",
    "\n",
    "    \n",
    "    # Compute the co-ocurrence matrix\n",
    "    make_cooccurence_matrix(rare_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75648a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visual2\n",
    "#I would like to see a diagram that shows the success percentages per label plottet against the amoint of training data per label\n",
    "\n",
    "if exec_visualize == True:\n",
    "    \n",
    "    Y_val = np.array(train_results_val)\n",
    "    Y_hat_val_binary = np.array(prediction_val[label_list])\n",
    "    \n",
    "    label_prediction_success = np.multiply(Y_val,Y_hat_val_binary)\n",
    "    nr_rows = label_prediction_success.shape[0]\n",
    "    \n",
    "    nr_successes, nr_true, nr_successes_percent = [], [], []\n",
    "    for class_, idx in label_dict.items():\n",
    "        nr_successes.append(label_prediction_success[:, idx].sum())\n",
    "        nr_true.append(Y_val[:, idx].sum())\n",
    "        nr_successes_percent.append((label_prediction_success[:, idx].sum())/(Y_val[:, idx].sum()))\n",
    "    go.Figure([\n",
    "        go.Bar(x=list(label_dict), y=nr_successes, name=\"success\"),\n",
    "        go.Bar(x=list(label_dict), y=nr_true, name=\"true\")\n",
    "#         go.Bar(x=list(label_dict), y=nr_successes_percent, name=\"success rate\")\n",
    "    ]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb9191e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if exec_visualize == True:\n",
    "    #visual3\n",
    "    #I would like to see the confusion matrices per label\n",
    "    fig = make_subplots(cols=5, rows=4)\n",
    "    for jdx in range(Y_val.shape[1]):\n",
    "        y_val = Y_val[:, jdx].ravel()\n",
    "        y_hat_val = (Y_hat_val[:, jdx].ravel() > 0.2).astype(float)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_val, y_hat_val).ravel()\n",
    "        mat = np.array([[fn, tn], [tp, fp]])\n",
    "        col = jdx // 4+1\n",
    "        row = jdx % 4+1\n",
    "        fig.add_trace(\n",
    "            go.Heatmap(\n",
    "                z=mat, text=[[f\"fn: {fn}\", f\"tn: {tn}\"], [f\"tp: {tp}\", f\"fp: {fp}\"]], \n",
    "                texttemplate=\"%{text}\", colorscale='Viridis', name=list(label_dict.keys())[jdx],\n",
    "                showscale=False\n",
    "            ),\n",
    "            col=col, row=row, \n",
    "        )\n",
    "        fig.update_xaxes(title=list(label_dict.keys())[jdx], showticklabels=False, row=row, col=col)\n",
    "        fig.update_yaxes(showticklabels=False, row=row, col=col)\n",
    "\n",
    "\n",
    "    fig.update_layout(\n",
    "        width=1200, height=800, title=\"Confusion matrices\", \n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e697c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
